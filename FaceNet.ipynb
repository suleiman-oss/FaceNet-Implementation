{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "C_eGYxMWAxPv",
    "outputId": "1b9a8690-25ef-461d-a4dd-ff1ccca8b8ec"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "!pip install mtcnn\n",
    "import mtcnn\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from os import listdir\n",
    "from matplotlib import pyplot\n",
    "from os.path import isdir\n",
    "from numpy import savez_compressed\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "# Load the model\n",
    "model=load_model('/facenet_keras.h5')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zV_UJDVsBNLG"
   },
   "outputs": [],
   "source": [
    "# Extract face pixels from a given image.\n",
    "def faceExt(imgpath, size=(160,160)):\n",
    "  img=Image.open(imgpath)\n",
    "  img=img.convert('RGB')\n",
    "  pix=asarray(img)\n",
    "  detector=MTCNN()\n",
    "  results=detector.detect_faces(pix)\n",
    "  x1,y1,wd,ht=results[0]['box']\n",
    "  x1,y1=abs(x1),abs(y1)\n",
    "  x2,y2=x1+wd,y1+ht\n",
    "  #print('ordinates')\n",
    "  #print(x1,y1,x2,y2) \n",
    "  face=pix[y1:y2,x1:x2]\n",
    "  img=Image.fromarray(face)\n",
    "  img=img.resize(size)\n",
    "  farray=asarray(img)\n",
    "  return farray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBHCg5tZB4FO"
   },
   "outputs": [],
   "source": [
    "# Load faces from images stored in the given directory.\n",
    "def load_faces(dir):\n",
    "  faces=[]  \n",
    "  for file in listdir(dir):\n",
    "    path=dir+'/'+file`\n",
    "    try:\n",
    "      face=faceExt(path)\n",
    "    except Exception as er:\n",
    "      print(file)\n",
    "    faces.append(face)\n",
    "  return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbYrJwkbB-Wj"
   },
   "outputs": [],
   "source": [
    "# Provide the path for the dataset directory to extract faces from the dataset using the aforementioned functions.\n",
    "def load_dataset(directory):\n",
    "  x=[]\n",
    "  y=[]\n",
    "  #print(listdir(directory))\n",
    "  for subdir in listdir(directory):\n",
    "    #print(subdir)\n",
    "    path = directory + subdir \n",
    "    #print(path)\n",
    "    if not isdir(path):\n",
    "      continue\n",
    "    try:\n",
    "      faces = load_faces(path)\n",
    "    except Exception as er:\n",
    "      print(er)\n",
    "    labels = [subdir for _ in range(len(faces))]\n",
    "    print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "    x.extend(faces)\n",
    "    y.extend(labels)\n",
    "  return asarray(x),asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "M2XfvaF9CC5N",
    "outputId": "68027547-250a-42f5-d4e8-03f3f887a496"
   },
   "outputs": [],
   "source": [
    "trainX, trainy = load_dataset('/train/')# path for train dataset\n",
    "print(trainX.shape, trainy.shape)\n",
    "testX, testy = load_dataset('/val/')# path for test dataset\n",
    "savez_compressed('faces_dataset.npz', trainX, trainy, testX, testy)# Save the extracted faces from the dataset as a compressed file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mOAWFR2iCHiJ",
    "outputId": "71aa863a-78d0-4184-8d83-3d3ffeaac906"
   },
   "outputs": [],
   "source": [
    "data = load('faces_dataset.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RS4-Dz3rCRCF"
   },
   "outputs": [],
   "source": [
    "# Extraxt face embeddings by traversing the face pixels through the FaceNet model.\n",
    "def get_embedding(model,face):\n",
    "  face=face.astype('float32')\n",
    "  mean=face.mean()\n",
    "  std=face.std()\n",
    "  face=(face-mean)/std\n",
    "  sample=expand_dims(face,axis=0)\n",
    "  embedding=model.predict(sample)\n",
    "  return embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "J5CpqVEeCWNY",
    "outputId": "17d118e7-6b9e-426f-fe6e-f3e4593f5d2b"
   },
   "outputs": [],
   "source": [
    "emd_train=[]\n",
    "for face in trainX:\n",
    "  embedding=get_embedding(model,face)\n",
    "  emd_train.append(embedding)\n",
    "emd_train=asarray(emd_train)\n",
    "emd_test=[]\n",
    "for face in testX:\n",
    "  embedding=get_embedding(model,face)\n",
    "  emd_test.append(embedding)\n",
    "emd_test=asarray(emd_test)\n",
    "savez_compressed('face_embeddings.npz',emd_train,trainy,emd_test,testy)# save embeddings as a compressed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vEZwIMjBCht1",
    "outputId": "6cb4da65-c8b1-454a-8fd5-4bbf63ae7d5a"
   },
   "outputs": [],
   "source": [
    "# Train the SVM model based on the face embeddings.\n",
    "data = load('face_embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "incoder=Normalizer(norm='l2')\n",
    "trainX=incoder.transform(trainX)\n",
    "testX=incoder.transform(testX)\n",
    "outcoder=LabelEncoder()\n",
    "outcoder.fit(trainy)\n",
    "trainy=outcoder.transform(trainy)\n",
    "testy=outcoder.transform(testy)\n",
    "model=SVC(kernel='linear',probability=True)\n",
    "model.fit(trainX,trainy)\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juRm1XVJCnCe"
   },
   "outputs": [],
   "source": [
    "# Function to draw face contours with the identity of the person.\n",
    "def draw(filename,name):\n",
    "  im=Image.open(filename)\n",
    "  im=im.convert('RGB')\n",
    "  pix=asarray(im)\n",
    "  detector=MTCNN()\n",
    "  results=detector.detect_faces(pix)  \n",
    "  x1,y1,wd,ht=results[0]['box']\n",
    "  x1,y1=abs(x1),abs(y1)\n",
    "  img = matplotlib.image.imread(filename)\n",
    "  figure, ax = pyplot.subplots(1)\n",
    "  rect = patches.Rectangle((x1,y1),wd,ht, edgecolor='r', facecolor=\"none\")\n",
    "  ax.imshow(im)\n",
    "  ax.add_patch(rect)\n",
    "  ax.text(x1,y1,name,style ='italic', fontsize = 12,color='black', bbox ={'facecolor':'white','alpha':0.6, 'pad':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30fFeA3hCuyl"
   },
   "outputs": [],
   "source": [
    "def recognize(path):\n",
    "  face_pixels=faceExt(path)\n",
    "  face_embedding=get_embedding(load_model('/facenet_keras.h5'),face_pixels)\n",
    "  samples=expand_dims(face_embedding,axis=0)\n",
    "  predicted_class=model.predict(samples)\n",
    "  predicted_probability=model.predict_proba(samples)\n",
    "  if predicted_probability[0,predicted_class[0]]>0.65:\n",
    "    name=outcoder.inverse_transform(predicted_class)\n",
    "    draw(path,name[0])\n",
    "  else:\n",
    "    draw(path,'unknown person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize('train/ben_afflek/httpcsvkmeuaeccjpg.jpg')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FaceNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
